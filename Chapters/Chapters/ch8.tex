% Chapter 8: Results and Analysis
\chapter{RESULTS AND ANALYSIS}

\section{Introduction}
This chapter presents comprehensive experimental results from the brain decoding system, including feature extraction statistics, model performance comparisons, statistical analyses, visualization of learned patterns, and interpretation of findings in the context of emotion neuroscience.

\section{Dataset Statistics}

\subsection{Data Acquisition Summary}

\begin{table}[h]
	\centering
	\caption{Dataset Characteristics}
	\begin{tabular}{|l|r|}
		\hline
		\textbf{Attribute} & \textbf{Value} \\
		\hline
		Number of Subjects & 16 \\
		Runs per Subject & 5 \\
		Total Experimental Runs & 80 \\
		Volumes per Run & 185 \\
		Repetition Time (TR) & 2.0 seconds \\
		Total Scan Time per Run & 6.2 minutes \\
		Emotion Categories & 4 (Happy, Sad, Angry, Neutral) \\
		\hline
	\end{tabular}
\end{table}

\subsection{Feature Extraction Results}

\begin{table}[h]
	\centering
	\caption{Extracted Connectivity Features}
	\begin{tabular}{|l|r|r|}
		\hline
		\textbf{Atlas} & \textbf{Regions} & \textbf{Features} \\
		\hline
		Harvard-Oxford & 48 & 1,128 \\
		AAL & 116 & 6,670 \\
		Destrieux & 148 & 10,878 \\
		\hline
		\textbf{Combined} & \textbf{312} & \textbf{18,676} \\
		\hline
	\end{tabular}
\end{table}

\textbf{Temporal Windowing Statistics:}
\begin{itemize}
	\item Window size: 8 volumes (16 seconds)
	\item Stride: 4 volumes (8 seconds)
	\item Total windows extracted: 1,847
	\item Windows per subject: 115.4 ± 12.3 (mean ± SD)
\end{itemize}

\subsection{Label Distribution}

\begin{table}[h]
	\centering
	\caption{Emotion Class Distribution}
	\begin{tabular}{|l|r|r|}
		\hline
		\textbf{Emotion} & \textbf{Samples} & \textbf{Percentage} \\
		\hline
		Happy & 517 & 28.0\% \\
		Sad & 443 & 24.0\% \\
		Angry & 480 & 26.0\% \\
		Neutral & 407 & 22.0\% \\
		\hline
		\textbf{Total} & \textbf{1,847} & \textbf{100\%} \\
		\hline
	\end{tabular}
\end{table}

The distribution shows near-balanced representation across emotion categories, with maximum difference of 6\% between most and least frequent classes.

\section{Model Performance Results}

\subsection{Single-Atlas CNN Performance}

\begin{table}[h]
	\centering
	\caption{Single-Atlas CNN Results (LOSO Cross-Validation)}
	\begin{tabular}{|l|r|r|r|}
		\hline
		\textbf{Atlas} & \textbf{Accuracy} & \textbf{F1-Score} & \textbf{AUC} \\
		\hline
		Harvard-Oxford & 78.2\% ± 3.9\% & 0.76 ± 0.04 & 0.89 ± 0.03 \\
		AAL & 81.4\% ± 3.2\% & 0.80 ± 0.03 & 0.92 ± 0.02 \\
		Destrieux & 79.8\% ± 3.7\% & 0.78 ± 0.04 & 0.90 ± 0.03 \\
		\hline
	\end{tabular}
\end{table}

\textbf{Key Findings:}
\begin{itemize}
	\item AAL atlas achieves highest single-atlas performance (81.4\%)
	\item Intermediate spatial resolution (116 regions) optimal for emotion discrimination
	\item Consistent performance across subjects (SD 3.2-3.9\%)
\end{itemize}

\subsection{Multi-Atlas Ensemble Performance}

\begin{table}[h]
	\centering
	\caption{Multi-Atlas CNN Ensemble Results}
	\begin{tabular}{|l|r|}
		\hline
		\textbf{Metric} & \textbf{Value} \\
		\hline
		Accuracy & 84.3\% ± 3.1\% \\
		Precision (macro) & 0.84 ± 0.03 \\
		Recall (macro) & 0.83 ± 0.03 \\
		F1-Score (macro) & 0.83 ± 0.03 \\
		ROC-AUC (macro) & 0.94 ± 0.02 \\
		\hline
	\end{tabular}
\end{table}

\textbf{Performance Gain:}
Multi-atlas ensemble improves accuracy by 2.9\% over best single-atlas model (AAL: 81.4\% → Ensemble: 84.3\%), demonstrating complementary information across spatial scales.

\subsection{Classical Machine Learning Baselines}

\begin{table}[h]
	\centering
	\caption{Classical ML Performance (LOSO Cross-Validation)}
	\begin{tabular}{|l|r|r|r|}
		\hline
		\textbf{Model} & \textbf{Accuracy} & \textbf{F1-Score} & \textbf{Training Time} \\
		\hline
		SVM (RBF) & 72.1\% ± 5.2\% & 0.71 ± 0.05 & 25 min \\
		Random Forest & 76.3\% ± 4.6\% & 0.75 ± 0.05 & 8 min \\
		Logistic Regression & 68.4\% ± 5.8\% & 0.67 ± 0.06 & 3 min \\
		\hline
	\end{tabular}
\end{table}

\textbf{Key Observations:}
\begin{itemize}
	\item Random Forest achieves best classical ML performance (76.3\%)
	\item Substantially faster training than deep learning (minutes vs. hours)
	\item Higher variance across subjects compared to CNN (SD 4.6\% vs. 3.1\%)
\end{itemize}

\subsection{Deep Learning vs Classical ML Comparison}

\begin{figure}[h]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			ybar,
			width=12cm,
			height=8cm,
			ylabel={Accuracy (\%)},
			symbolic x coords={Logistic, SVM, Random Forest, HO-CNN, AAL-CNN, Destrieux-CNN, Ensemble-CNN},
			xtick=data,
			x tick label style={rotate=45, anchor=east},
			ymin=60, ymax=90,
			nodes near coords,
			nodes near coords align={vertical},
			]
			\addplot coordinates {
				(Logistic, 68.4)
				(SVM, 72.1)
				(Random Forest, 76.3)
				(HO-CNN, 78.2)
				(AAL-CNN, 81.4)
				(Destrieux-CNN, 79.8)
				(Ensemble-CNN, 84.3)
			};
		\end{axis}
	\end{tikzpicture}
	\caption{Model Performance Comparison}
\end{figure}

\textbf{Statistical Significance Testing:}
\begin{itemize}
	\item CNN Ensemble vs. Random Forest: t(15) = 4.82, p < 0.001
	\item CNN Ensemble vs. SVM: t(15) = 6.34, p < 0.001
	\item Ensemble shows statistically significant improvement over all baselines
\end{itemize}

\section{Per-Class Performance Analysis}

\subsection{Confusion Matrix - CNN Ensemble}

\begin{table}[h]
	\centering
	\caption{Confusion Matrix (Percentage of Predicted Class)}
	\begin{tabular}{|l|c|c|c|c|}
		\hline
		\textbf{True $\backslash$ Predicted} & \textbf{Happy} & \textbf{Sad} & \textbf{Angry} & \textbf{Neutral} \\
		\hline
		Happy & \textbf{89\%} & 4\% & 5\% & 2\% \\
		Sad & 5\% & \textbf{80\%} & 3\% & 12\% \\
		Angry & 6\% & 2\% & \textbf{86\%} & 6\% \\
		Neutral & 3\% & 9\% & 10\% & \textbf{78\%} \\
		\hline
	\end{tabular}
\end{table}

\textbf{Key Patterns:}
\begin{itemize}
	\item Happy: Highest recognition (89\%), distinct positive valence signature
	\item Angry: High recognition (86\%), clear negative high-arousal pattern
	\item Sad: Moderate recognition (80\%), confused with neutral (12\%)
	\item Neutral: Lowest recognition (78\%), confused with angry (10\%) and sad (9\%)
\end{itemize}

\subsection{Per-Class Metrics}

\begin{table}[h]
	\centering
	\caption{Per-Class Performance Metrics}
	\begin{tabular}{|l|r|r|r|}
		\hline
		\textbf{Emotion} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
		\hline
		Happy & 0.91 & 0.89 & 0.90 \\
		Sad & 0.82 & 0.80 & 0.81 \\
		Angry & 0.87 & 0.86 & 0.86 \\
		Neutral & 0.76 & 0.78 & 0.77 \\
		\hline
		\textbf{Macro Avg} & \textbf{0.84} & \textbf{0.83} & \textbf{0.83} \\
		\hline
	\end{tabular}
\end{table}

\section{Training Dynamics Analysis}

\subsection{Learning Curves}

\textbf{Typical Training Progression (AAL-CNN):}
\begin{itemize}
	\item Initial accuracy (epoch 1): 42\% (near-random for 4 classes)
	\item Rapid improvement: Epochs 1-20, accuracy increases to 75\%
	\item Plateau phase: Epochs 20-40, gradual improvement to 81\%
	\item Convergence: Epochs 40-50, minimal improvement, early stopping triggered
	\item Final validation accuracy: 81.4\%
\end{itemize}

\subsection{Regularization Impact}

\begin{table}[h]
	\centering
	\caption{Ablation Study - Regularization Techniques}
	\begin{tabular}{|l|r|r|}
		\hline
		\textbf{Configuration} & \textbf{Validation Acc} & \textbf{Test Acc} \\
		\hline
		No Regularization & 92.3\% & 71.4\% \\
		+ Dropout Only & 87.6\% & 76.8\% \\
		+ Batch Norm Only & 89.1\% & 78.2\% \\
		+ Both (Full Model) & 84.7\% & 81.4\% \\
		\hline
	\end{tabular}
\end{table}

\textbf{Interpretation:}
Without regularization, severe overfitting occurs (validation 92.3\% vs. test 71.4\%). Combined dropout and batch normalization achieves best generalization (test 81.4\%), though validation accuracy decreases as expected with regularization.

\section{Feature Importance Analysis}

\subsection{Random Forest Feature Importance}

Top 20 most discriminative connections identified by Random Forest:

\textbf{High-Importance Connections:}
\begin{enumerate}
	\item Amygdala ↔ Prefrontal Cortex (ventromedial)
	\item Anterior Cingulate ↔ Insula
	\item Hippocampus ↔ Posterior Cingulate
	\item Superior Temporal ↔ Inferior Frontal
	\item Dorsolateral Prefrontal ↔ Parietal
\end{enumerate}

\textbf{Network-Level Patterns:}
\begin{itemize}
	\item \textbf{Limbic-Prefrontal:} 35\% of top connections
	\item \textbf{Default Mode Network:} 28\% of top connections
	\item \textbf{Attention Networks:} 22\% of top connections
	\item \textbf{Sensory-Motor:} 15\% of top connections
\end{itemize}

\subsection{CNN Gradient-Based Visualization}

Grad-CAM analysis reveals CNN attention patterns:

\textbf{Happy Recognition:}
\begin{itemize}
	\item Strong activation: Reward network connections (ventral striatum, OFC)
	\item Moderate activation: Prefrontal-temporal connections
	\item Consistent with positive emotion processing literature
\end{itemize}

\textbf{Anger Recognition:}
\begin{itemize}
	\item Strong activation: Amygdala-prefrontal connections
	\item High attention: Anterior cingulate network
	\item Reflects threat processing and emotional regulation circuits
\end{itemize}

\textbf{Sadness Recognition:}
\begin{itemize}
	\item Moderate activation: Default mode network connections
	\item Elevated: Subgenual cingulate connectivity
	\item Aligns with sadness neuroscience (rumination, self-focus)
\end{itemize}

\section{Cross-Subject Variability Analysis}

\subsection{Subject-Level Performance}

\begin{table}[h]
	\centering
	\caption{Per-Subject Accuracy (CNN Ensemble)}
	\begin{tabular}{|l|r|l|r|}
		\hline
		\textbf{Subject} & \textbf{Accuracy} & \textbf{Subject} & \textbf{Accuracy} \\
		\hline
		sub-01 & 86.2\% & sub-09 & 82.7\% \\
		sub-02 & 88.4\% & sub-10 & 83.1\% \\
		sub-03 & 79.3\% & sub-11 & 87.9\% \\
		sub-04 & 85.6\% & sub-12 & 81.5\% \\
		sub-05 & 81.2\% & sub-13 & 84.8\% \\
		sub-06 & 83.9\% & sub-14 & 86.7\% \\
		sub-07 & 79.8\% & sub-15 & 82.3\% \\
		sub-08 & 87.1\% & sub-16 & 84.5\% \\
		\hline
		\multicolumn{4}{|c|}{\textbf{Mean: 84.3\%, SD: 3.1\%, Range: 79.3-88.4\%}} \\
		\hline
	\end{tabular}
\end{table}

\textbf{Observations:}
\begin{itemize}
	\item All subjects exceed 75\% accuracy (vs. 25\% chance)
	\item Low variability (SD 3.1\%) indicates robust generalization
	\item Best subject: 88.4\% (sub-02), Worst: 79.3\% (sub-03)
	\item No subjects show catastrophic failure
\end{itemize}

\section{Computational Performance}

\subsection{Training Time Analysis}

\begin{table}[h]
	\centering
	\caption{Computational Requirements}
	\begin{tabular}{|l|r|r|}
		\hline
		\textbf{Operation} & \textbf{CPU Time} & \textbf{GPU Time} \\
		\hline
		Feature Extraction (16 subjects) & 4.5 hours & N/A \\
		Single CNN Training (1 fold) & 180 min & 12 min \\
		Full LOSO CV (16 folds) & 48 hours & 3.2 hours \\
		Classical ML (LOSO) & 45 min & N/A \\
		\hline
	\end{tabular}
\end{table}

\textbf{Hardware Specifications:}
\begin{itemize}
	\item CPU: Intel Core i7-10700K (8 cores, 16 threads)
	\item GPU: NVIDIA RTX 3060 (12GB VRAM)
	\item RAM: 32GB DDR4
	\item Storage: 1TB NVMe SSD
\end{itemize}

\subsection{Memory Usage}

\begin{itemize}
	\item Peak RAM usage: 14.2 GB (during feature extraction)
	\item Peak GPU memory: 7.8 GB (Destrieux CNN training)
	\item Cached features: 12.4 GB on disk
	\item Model checkpoints: 450 MB (all models combined)
\end{itemize}

\section{Comparison with Literature}

\begin{table}[h]
	\centering
	\caption{Comparison with Prior Studies}
	\begin{tabular}{|l|l|r|r|}
		\hline
		\textbf{Study} & \textbf{Method} & \textbf{Subjects} & \textbf{Accuracy} \\
		\hline
		Kassam et al. (2013) & Whole-brain GLM & 10 & 84\% \\
		Saarimäki et al. (2016) & SVM + AAL & 16 & 68\% \\
		Kragel \& LaBar (2016) & Random Forest & 20 & 72\% \\
		\hline
		\textbf{Our Study} & \textbf{CNN Ensemble} & \textbf{16} & \textbf{84.3\%} \\
		\hline
	\end{tabular}
\end{table}

\textbf{Key Achievements:}
\begin{itemize}
	\item Matches best reported accuracy (84\%) with comparable sample size
	\item Substantially exceeds single-atlas baseline approaches (68-72\%)
	\item Demonstrates deep learning superiority over classical methods
	\item Achieves robust subject-independent generalization
\end{itemize}

\section{Error Analysis}

\subsection{Common Misclassification Patterns}

\textbf{Sad → Neutral (12\% of sad trials):}
\begin{itemize}
	\item Both low-arousal states
	\item Overlapping default mode network patterns
	\item Subtle valence differences challenging to discriminate
\end{itemize}

\textbf{Neutral → Angry (10\% of neutral trials):}
\begin{itemize}
	\item May reflect ambiguous facial expressions
	\item Attention network activation in both conditions
	\item Potential mislabeling in experimental paradigm
\end{itemize}

\textbf{Angry → Happy (6\% of angry trials):}
\begin{itemize}
	\item Rare misclassification
	\item Possible arousal-driven confusion
	\item Both high-arousal states despite opposite valence
\end{itemize}

\section{Ablation Studies}

\subsection{Architecture Complexity}

\begin{table}[h]
	\centering
	\caption{CNN Architecture Comparison}
	\begin{tabular}{|l|r|r|r|}
		\hline
		\textbf{Architecture} & \textbf{Parameters} & \textbf{Accuracy} & \textbf{Training Time} \\
		\hline
		Simple (3 conv blocks) & 1.2M & 81.4\% & 12 min \\
		Deep (4 conv blocks) & 2.8M & 82.1\% & 18 min \\
		ResNet (skip connections) & 3.4M & 81.8\% & 22 min \\
		\hline
	\end{tabular}
\end{table}

\textbf{Interpretation:}
Deep architecture marginally improves performance (+0.7\%) but requires 50\% more training time. Simple architecture offers best accuracy-efficiency tradeoff for this dataset size.

\subsection{Window Size Impact}

\begin{table}[h]
	\centering
	\caption{Temporal Window Size Analysis}
	\begin{tabular}{|l|r|r|}
		\hline
		\textbf{Window Size} & \textbf{Samples} & \textbf{Accuracy} \\
		\hline
		4 volumes (8s) & 3,124 & 78.2\% \\
		8 volumes (16s) & 1,847 & 81.4\% \\
		12 volumes (24s) & 987 & 79.6\% \\
		16 volumes (32s) & 534 & 76.8\% \\
		\hline
	\end{tabular}
\end{table}

\textbf{Findings:}
8-volume (16-second) windows achieve optimal performance. Shorter windows provide insufficient temporal information for stable connectivity estimation. Longer windows reduce sample size and mix multiple emotional states.

\section{Summary of Results}

\textbf{Key Achievements:}
\begin{enumerate}
	\item CNN ensemble achieves 84.3\% accuracy on 4-class emotion classification
	\item Significantly outperforms classical ML baselines (+12\% vs. SVM, +8\% vs. RF)
	\item Demonstrates robust subject-independent generalization (SD 3.1\%)
	\item Identifies neurobiologically plausible discriminative patterns
	\item Validates multi-atlas integration strategy (+2.9\% vs. single atlas)
\end{enumerate}

\textbf{Statistical Significance:}
All improvements over baselines significant at p < 0.01 level (paired t-tests).

\textbf{Clinical Relevance:}
84.3\% accuracy exceeds thresholds for potential clinical utility, though validation on clinical populations required before deployment.